{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "lemm = WordNetLemmatizer()\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = pd.read_pickle(r\"C:\\Users\\PIYUSH\\Desktop\\validation_notscaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(r\"C:\\Users\\PIYUSH\\Downloads\\essay (1).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "      <th>word_count</th>\n",
       "      <th>vocab_count</th>\n",
       "      <th>n_count</th>\n",
       "      <th>v_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>freek</th>\n",
       "      <th>wrong_spell</th>\n",
       "      <th>beaut</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>1788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>8.771930</td>\n",
       "      <td>26</td>\n",
       "      <td>163.218737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>1789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>1.526718</td>\n",
       "      <td>25</td>\n",
       "      <td>154.934685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>1790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>471</td>\n",
       "      <td>137</td>\n",
       "      <td>91</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>13.170732</td>\n",
       "      <td>38</td>\n",
       "      <td>112.750824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>1791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>410</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>4.733728</td>\n",
       "      <td>38</td>\n",
       "      <td>156.539091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496</td>\n",
       "      <td>132</td>\n",
       "      <td>122</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>4.824561</td>\n",
       "      <td>54</td>\n",
       "      <td>141.841194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   domain1_predictionid  domain2_predictionid  word_count  vocab_count  \\\n",
       "0                  1788                   NaN         275           77   \n",
       "1                  1789                   NaN         353           95   \n",
       "2                  1790                   NaN         471          137   \n",
       "3                  1791                   NaN         410          103   \n",
       "4                  1792                   NaN         496          132   \n",
       "\n",
       "   n_count  v_count  adj_count  adv_count  sent_len  freek  wrong_spell  \\\n",
       "0       67       29         21         15        13     26     8.771930   \n",
       "1       75       35         15         21        20     33     1.526718   \n",
       "2       91       51         29         26        15     35    13.170732   \n",
       "3      103       49         21         17        24     31     4.733728   \n",
       "4      122       39         38         22        34     47     4.824561   \n",
       "\n",
       "   beaut  perplexity  \n",
       "0     26  163.218737  \n",
       "1     25  154.934685  \n",
       "2     38  112.750824  \n",
       "3     38  156.539091  \n",
       "4     54  141.841194  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4218, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12978, 39)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>vocab_count</th>\n",
       "      <th>n_count</th>\n",
       "      <th>v_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>freek</th>\n",
       "      <th>wrong_spell</th>\n",
       "      <th>beaut</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>8.771930</td>\n",
       "      <td>26</td>\n",
       "      <td>163.218737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>353</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>1.526718</td>\n",
       "      <td>25</td>\n",
       "      <td>154.934685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471</td>\n",
       "      <td>137</td>\n",
       "      <td>91</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>13.170732</td>\n",
       "      <td>38</td>\n",
       "      <td>112.750824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>4.733728</td>\n",
       "      <td>38</td>\n",
       "      <td>156.539091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496</td>\n",
       "      <td>132</td>\n",
       "      <td>122</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>4.824561</td>\n",
       "      <td>54</td>\n",
       "      <td>141.841194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  vocab_count  n_count  v_count  adj_count  adv_count  sent_len  \\\n",
       "0         275           77       67       29         21         15        13   \n",
       "1         353           95       75       35         15         21        20   \n",
       "2         471          137       91       51         29         26        15   \n",
       "3         410          103      103       49         21         17        24   \n",
       "4         496          132      122       39         38         22        34   \n",
       "\n",
       "   freek  wrong_spell  beaut  perplexity  \n",
       "0     26     8.771930     26  163.218737  \n",
       "1     33     1.526718     25  154.934685  \n",
       "2     35    13.170732     38  112.750824  \n",
       "3     31     4.733728     38  156.539091  \n",
       "4     47     4.824561     54  141.841194  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=data_val.iloc[:,[5,6,7,8,9,10,11,12,13,14,15]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=MinMaxScaler()\n",
    "result=[]\n",
    "def scaling_features(i,feat,result):\n",
    "    d=((data_val[data_val['essay_set'] == i])[feat])\n",
    "    x=np.array(d)\n",
    "    x=np.reshape(x,(x.shape[0],1))\n",
    "    d=(sc.fit_transform(x))\n",
    "    result.append(d)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\piyush\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "col=['vocab_count',\n",
    "       'word_count', 'n_count', 'v_count', 'adj_count', 'adv_count',\n",
    "       'sent_len', 'freek', 'wrong_spell','beaut', 'perplexity']\n",
    "for name in col:\n",
    "    r=[]\n",
    "    for i in range(1,9):\n",
    "        r=scaling_features(i,name,r)\n",
    "    flat = [x for sublist in r for x in sublist]\n",
    "    result=[]\n",
    "    for i in flat:\n",
    "        result.append(i[0])\n",
    "    data_val[name]=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max((data_val[data_val['essay_set'] == 4])[\"n_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=MinMaxScaler()\n",
    "result=[]\n",
    "def scaling_features(i,feat,result):\n",
    "    d=((data[data['essay_set'] == i])[feat])\n",
    "    x=np.array(d)\n",
    "    x=np.reshape(x,(x.shape[0],1))\n",
    "    d=(sc.fit_transform(x))\n",
    "    result.append(d)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\piyush\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "col=['vocab_count',\n",
    "       'word_count', 'n_count', 'v_count', 'adj_count', 'adv_count',\n",
    "       'sent_len', 'freek', 'wrong_spell','beaut', 'perplexity']\n",
    "for name in col:\n",
    "    r=[]\n",
    "    for i in range(1,9):\n",
    "        r=scaling_features(i,name,r)\n",
    "    flat = [x for sublist in r for x in sublist]\n",
    "    result=[]\n",
    "    for i in flat:\n",
    "        result.append(i[0])\n",
    "    data[name]=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max((data_val[data_val['essay_set'] == 4])[\"n_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.to_pickle(r\"C:\\Users\\PIYUSH\\Downloads\\val_set_wise.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(r\"C:\\Users\\PIYUSH\\Downloads\\val_set_wise.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=max((df[df['essay_set'] == 3])[\"word_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
